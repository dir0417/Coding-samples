{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19ChbzITB31PxTlFdUvW9qxzz3NybFarS","timestamp":1711639606161}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","**1. importing modules**\n","\n","Always run steps 1 and 2 first, then you can run the others separately.\n"],"metadata":{"id":"Q_zHlecvrXrZ"}},{"cell_type":"code","source":["# importing modules\n","import pandas as pd\n","import os\n","from datetime import date\n","from datetime import datetime\n","import time\n","import openpyxl\n","from openpyxl.worksheet.datavalidation import DataValidation\n","import gc\n","from openpyxl import load_workbook"],"metadata":{"id":"Edop7vFsHkid","executionInfo":{"status":"ok","timestamp":1712248427601,"user_tz":360,"elapsed":2366,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["**2. merging all the tabs into one file**\n","\n","first, download the list of users from EMR (**logging in --> menu --> setup --> users --> there is a button left next to \"create users\" called \"export\", click on \"export\" --> wait for the file to load and export to location of choice in computer**), upload this file into co-laboratories, change the pathway to the file on \"excel_file\", run the script, then wait for an output file called \"merged_data\" to come out.\n","\n","This code does several things:\n","\n","1. It reads data from an Excel file with multiple sheets into separate dataframes.\n","2. It merges these dataframes together based on a common column ('Username' in this case).\n","3. It then writes the merged dataframe into a new Excel file.\n","\n","So, basically, it's combining information from different sheets in an Excel file into one big sheet and saving it as a new file."],"metadata":{"id":"ImjrffN8IGc_"}},{"cell_type":"code","source":["# Read Excel sheets into dataframes\n","excel_file = \"/content/Colorado_Users_03_29_2024_12_02.xlsx\"\n","sheet_names = [\"Profile\", \"Notification Addresses\", \"Roles\", \"Resource Associations\"]  # Replace with your sheet names\n","dfs = {}  # Dictionary to store dataframes\n","for sheet_name in sheet_names:\n","    dfs[sheet_name] = pd.read_excel(excel_file, sheet_name=sheet_name)\n","\n","# Merge dataframes based on the 'username' column\n","merged_df = None\n","for df in dfs.values():\n","    if merged_df is None:\n","        merged_df = df\n","    else:\n","        merged_df = pd.merge(merged_df, df, on='Username', how='left')\n","\n","# Write merged dataframe to Excel\n","with pd.ExcelWriter(\"merged_data.xlsx\") as writer:\n","    merged_df.to_excel(writer, index=False, sheet_name=\"MergedSheet\")\n"],"metadata":{"id":"eaMMNuoeyF6R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. creating data for the \"role audit\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"Role audit\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","This code does several things with an Excel file:\n","\n","1. It reads data from an Excel file into a DataFrame (think of it as a table).\n","2. It removes duplicate rows based on specific columns (like removing repeated entries).\n","3. It loads the same Excel file again.\n","4. It creates a list of roles.\n","5. It adds new columns to the DataFrame for each role, marking them with checkmarks if a user has that role. If the user has more than one roles, it will not be grouped into one user (so that user may have duplicate username if they have multiple roles)\n","6. It writes this updated DataFrame to a new Excel file.\n","7. It adjusts the width of columns in the Excel file.\n","8. It saves the updated Excel file.\n","9. It reads the updated Excel file into a DataFrame again.\n","10. It selects specific columns from the DataFrame.\n","11. It saves the selected columns to another Excel file.\n","12. Finally, it prints a message confirming where the output file is saved.\n","\n","Copy and paste the results after doing that to the spreadsheet here \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"paJPYfpNYcIR"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\", \"Role\"], inplace=True)\n"],"metadata":{"id":"XmWLHcjxINao","executionInfo":{"status":"ok","timestamp":1712249045026,"user_tz":360,"elapsed":200136,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Load the Excel workbook\n","workbook = openpyxl.load_workbook('/content/merged_data.xlsx')\n","\n","# Assuming 'df' is your original DataFrame\n","data = pd.DataFrame(df)\n","\n","# Define a list of roles\n","roles = ['Behavioral Health - State Admin', 'Behavioral Health', 'Coroner', 'Dispatcher',\n","         'ED Admin / Hospital Admin', 'Emergency Dept.', 'Emergency Managers', 'ESF-8',\n","         'Fire / EMS', 'Health Facilities - State Admin', 'Health Facilities and Clinics',\n","         'Healthcare Coalition', 'Long Term Care', 'MRC - Medical Reserve Corp',\n","         'MSPDC - Event creation only', 'OEPR', 'Pharmacy', 'ReadOnly',\n","         'Regional Staff / HCC Cord', 'State System Administrator']\n","\n","# Add columns for each role with checkmarks\n","for role in roles:\n","    data[role] = data['Role'].apply(lambda x: 'â˜‘' if x == role else '')\n","\n","# Create an Excel writer object\n","excel_writer = pd.ExcelWriter('user_roles.xlsx', engine='openpyxl')\n","\n","# Write the DataFrame to the Excel file\n","data.to_excel(excel_writer, sheet_name='User Roles', index=False)\n","\n","# Save the Excel file\n","excel_writer.close()\n"],"metadata":{"id":"9oZ6Y5Ena6yy","executionInfo":{"status":"ok","timestamp":1712250088777,"user_tz":360,"elapsed":239868,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/user_roles.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Selecting only the desired columns\n","selected_columns = ['Username', 'Login Email', 'Last login', 'Behavioral Health - State Admin', 'Behavioral Health', 'Coroner', 'Dispatcher',\n","         'ED Admin / Hospital Admin', 'Emergency Dept.', 'Emergency Managers', 'ESF-8',\n","         'Fire / EMS', 'Health Facilities - State Admin', 'Health Facilities and Clinics',\n","         'Healthcare Coalition', 'Long Term Care', 'MRC - Medical Reserve Corp',\n","         'MSPDC - Event creation only', 'OEPR', 'Pharmacy', 'ReadOnly',\n","         'Regional Staff / HCC Cord', 'State System Administrator']\n","df_selected = df[selected_columns]\n","\n","# Saving the output to an Excel file\n","output_file = \"role_audit.xlsx\"\n","df_selected.to_excel(output_file, index=False)\n","\n","print(f\"Output saved to {output_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZKzRYBdCRJJ","executionInfo":{"status":"ok","timestamp":1712250834468,"user_tz":360,"elapsed":4193,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}},"outputId":"b58f4276-2103-431d-f801-3f1051ec3497"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Output saved to role_audit.xlsx\n"]}]},{"cell_type":"markdown","source":["**4. creating data for the \"resource\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"resource\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".  \n","\n","This script performs the following tasks:\n","\n","1. It reads an Excel file named \"merged_data.xlsx\" into a pandas DataFrame.\n","2. It groups the data by different combinations of columns ('Resource (Name)', 'Associated', 'Update', 'Report', 'Administer User', 'Can Assign (Yes/No)'), and counts the number of unique users (by counting unique usernames).\n","3. For each group, it drops duplicate entries, keeping only the last occurrence.\n","4. It merges these grouped dataframes into a single dataframe based on the 'Resource (Name)' column, using a left join strategy.\n","5. Finally, it saves the merged dataframe into a new Excel file named \"resource.xlsx\" without including the index.\n","\n","This script is analyzing user roles or permissions associated with different resources, and it consolidates this information into a single Excel file for further analysis or reporting.\n","\n","In the Excel spreadsheet, we specifically require counts for individuals who responded with 'yes.' Therefore, upon downloading the sheet, please filter out all instances of 'associated,' 'update,' 'report,' 'delegated admin,' and 'assign' where the response is 'No,' and input '0' for those entries. Copy and paste the results after doing that to the spreadsheet here \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"N8tpiQBREOyJ"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)"],"metadata":{"id":"ld9obq72-nKq","executionInfo":{"status":"ok","timestamp":1712251825579,"user_tz":360,"elapsed":207221,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Group by the \"Resource\" column and count the number of unique users\n","role_counts_1 = df.groupby(['Resource (Name)', 'Associated'])['Username'].nunique().reset_index()\n","role_counts_1 = role_counts_1.drop_duplicates(subset = 'Resource (Name)', keep = 'last')\n","role_counts_2 = df.groupby(['Resource (Name)', 'Update'])['Username'].nunique().reset_index()\n","role_counts_2 = role_counts_2.drop_duplicates(subset = 'Resource (Name)', keep = 'last')\n","role_counts_3 = df.groupby(['Resource (Name)', 'Report'])['Username'].nunique().reset_index()\n","role_counts_3 = role_counts_3.drop_duplicates(subset = 'Resource (Name)', keep = 'last')\n","role_counts_4 = df.groupby(['Resource (Name)', 'Delegated Admin'])['Username'].nunique().reset_index()\n","role_counts_4 = role_counts_4.drop_duplicates(subset = 'Resource (Name)', keep = 'last')\n","role_counts_5 = df.groupby(['Resource (Name)', 'Can Assign (Yes/No)'])['Username'].nunique().reset_index()\n","role_counts_5 = role_counts_5.drop_duplicates(subset = 'Resource (Name)', keep = 'last')"],"metadata":{"id":"yAzcHs6C0ZHG","executionInfo":{"status":"ok","timestamp":1712251840862,"user_tz":360,"elapsed":1607,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Merging multiple dataframes using a loop\n","dfs = [role_counts_1, role_counts_2, role_counts_3, role_counts_4, role_counts_5]\n","merged_multiple = role_counts_1  # Initialize with the first dataframe\n","\n","for i, df in enumerate(dfs[1:], start=2):  # Start from index 2 to use suffixes\n","    merged_multiple = pd.merge(merged_multiple, df, on='Resource (Name)', how='left', suffixes=('', f'_{i}'))\n","\n","# Save the merged data to a new Excel file\n","merged_multiple.to_excel('resource_tab.xlsx', index=False)\n"],"metadata":{"id":"_dQ16EW-v-I1","executionInfo":{"status":"ok","timestamp":1712252082896,"user_tz":360,"elapsed":1064,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["**5. creating data for the \"user\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"user\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","This code does several things:\n","\n","1. It reads data from an Excel file named \"merged_data.xlsx\" into a DataFrame.\n","2. It groups the data by different categories (like roles), counts the number of unique users for each category, and stores these counts in separate DataFrames.\n","3. It merges these separate DataFrames into one based on a common column, \"Username\".\n","4. It drops some unnecessary columns from the merged DataFrame.\n","5. Finally, it saves the merged and modified data into a new Excel file named \"user_tab.xlsx\".\n","\n","In the Excel spreadsheet, we specifically require counts for individuals who responded with 'yes.' Therefore, upon downloading the sheet, please filter out all instances of 'associated,' 'update,' 'report,' 'delegated admin,' and 'assign' where the response is 'No,' and input '0' for those entries. Copy and paste the results after doing that to the spreadsheet here \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"_xeNrRZ5o2Tf"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)"],"metadata":{"id":"a1eKMMfix5PU","executionInfo":{"status":"ok","timestamp":1712252406200,"user_tz":360,"elapsed":197311,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Group by the \"roles\" column and count the number of unique users\n","role_counts_1 = df.groupby(['Username', 'Associated'])['Resource (Name)'].nunique().reset_index()\n","role_counts_1 = role_counts_1.drop_duplicates(subset = 'Username', keep = 'last')\n","role_counts_2 = df.groupby(['Username', 'Update'])['Resource (Name)'].nunique().reset_index()\n","role_counts_2 = role_counts_2.drop_duplicates(subset = 'Username', keep = 'last')\n","role_counts_3 = df.groupby(['Username', 'Report'])['Resource (Name)'].nunique().reset_index()\n","role_counts_3 = role_counts_3.drop_duplicates(subset = 'Username', keep = 'last')\n","role_counts_4 = df.groupby(['Username', 'Delegated Admin'])['Resource (Name)'].nunique().reset_index()\n","role_counts_4 = role_counts_4.drop_duplicates(subset = 'Username', keep = 'last')\n","role_counts_5 = df.groupby(['Username', 'Can Assign (Yes/No)'])['Resource (Name)'].nunique().reset_index()\n","role_counts_5 = role_counts_5.drop_duplicates(subset = 'Username', keep = 'last')"],"metadata":{"id":"bQkANz2VIKNF","executionInfo":{"status":"ok","timestamp":1712252529962,"user_tz":360,"elapsed":1910,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Merging multiple dataframes using a loop\n","dfs = [role_counts_1, role_counts_2, role_counts_3, role_counts_4, role_counts_5]\n","merged_multiple = role_counts_1  # Initialize with the first dataframe\n","\n","for i, df in enumerate(dfs[1:], start=2):  # Start from index 2 to use suffixes\n","    merged_multiple = pd.merge(merged_multiple, df, on='Username', how='left', suffixes=('', f'_{i}'))\n","\n","# Save the merged data to a new Excel file\n","merged_multiple.to_excel('user_tab.xlsx', index=False)\n"],"metadata":{"id":"jtbrnBr4kR9N","executionInfo":{"status":"ok","timestamp":1712252799970,"user_tz":360,"elapsed":735,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["\n","**6. creating data for the \"users by year\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"users by year\" on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","Here's what's happening in simpler terms:\n","\n","1. The code reads data from an Excel file named \"merged_data.xlsx\" and stores it in a pandas DataFrame (a table-like structure for handling data in Python).\n","\n","2. It removes any duplicate rows in the DataFrame based on the \"Username\" column. This ensures each user appears only once in the data.\n","\n","3. It saves the cleaned data (without duplicates) into a new Excel file named \"result.xlsx\".\n","\n","4. It reads the cleaned data from \"result.xlsx\" into another DataFrame called \"data\".\n","\n","5. It converts the \"Last login\" column in the DataFrame to datetime format, which is a special type for handling dates and times in Python.\n","\n","6. It extracts the year from the \"Last login\" column and creates a new column named \"login_year\" to store these years.\n","\n","7. It counts the number of users for each year based on their last login and stores this count in a new DataFrame called \"user_counts\".\n","\n","8. Finally, it saves the user counts for each year into a new Excel file named \"users_by_year.xlsx\".\n","\n","In short, this code reads data from an Excel file, cleans it by removing duplicates, analyzes login information by extracting years, and saves the results into new Excel files.\n","\n","Copy and paste results on this \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"NONxKtdKl4sM"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('result.xlsx', index=False)"],"metadata":{"id":"vYTvOl9JSQ1u","executionInfo":{"status":"ok","timestamp":1712253057709,"user_tz":360,"elapsed":191422,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Read your data into a pandas DataFrame\n","data = pd.read_excel(\"/content/result.xlsx\")  # Replace \"your_data.csv\" with your actual file path\n","\n","# Convert the last login column to datetime format\n","data['last_login'] = pd.to_datetime(data['Last login'])\n","\n","# Extract the year from the last login column\n","data['login_year'] = data['last_login'].dt.year\n","\n","# Count the number of users per year\n","user_counts = data['login_year'].value_counts().sort_index()\n","\n","print(user_counts)\n","\n","# Save the merged data to a new Excel file\n","user_counts.to_excel('users_by_year.xlsx', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8u5G6znIKhew","executionInfo":{"status":"ok","timestamp":1712253190955,"user_tz":360,"elapsed":1315,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}},"outputId":"2e08e062-e174-4216-e1b0-46a186f45b32"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["login_year\n","2010.0       1\n","2011.0       1\n","2012.0       7\n","2013.0       5\n","2014.0       6\n","2015.0      16\n","2016.0      26\n","2017.0      17\n","2018.0      25\n","2019.0      23\n","2020.0     164\n","2021.0     353\n","2022.0     508\n","2023.0    1089\n","2024.0     882\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["**7. creating data for the \"last login 180 days to 365 days ago\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"last login 180 days to 365 days ago\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","This code does a few things:\n","\n","1. It reads an Excel file called \"merged_data.xlsx\" into a DataFrame.\n","2. It removes duplicate rows based on the \"Username\" column.\n","3. It saves the cleaned data into a new Excel file called \"result.xlsx\".\n","4. It converts a column named \"Last login\" into datetime format.\n","5. It calculates today's date.\n","6. It calculates the date 180 days ago and the date 365 days ago from today's date.\n","7. It selects rows from the DataFrame where the \"Last login\" date falls between 180 and 365 days ago.\n","8. It saves the selected data into a new Excel file called \"last_login_180_days_to_365_days_ago.xlsx\".\n","\n","Overall, it cleans and filters data related to user logins and saves the filtered data into a new Excel file.\n","\n","Copy and paste results on this \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"vA6K6DfAL-I1"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('result.xlsx', index=False)"],"metadata":{"id":"5C4jC6LWMLel","executionInfo":{"status":"ok","timestamp":1712253394908,"user_tz":360,"elapsed":88339,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Assuming your DataFrame is named df and the column containing the last login dates is 'Last login'\n","# First, convert 'Last login' column to datetime if it's not already in datetime format\n","df['Date'] = pd.to_datetime(df['Last login'])\n","\n","# Then, calculate today's date\n","today = pd.to_datetime('today')\n","\n","# Calculate the date 180 days ago\n","start_date = today - pd.Timedelta(days=365)\n","\n","# Calculate the date 365 days ago\n","end_date = today - pd.Timedelta(days=180)\n","\n","# Select data within the specified range\n","selected_data = df[(df['Last login'] >= start_date) & (df['Last login'] <= end_date)]\n","\n","# Now selected_data contains the rows where the last login was between 180 and 365 days ago\n","\n","\n","# Save the merged data to a new Excel file\n","selected_data.to_excel('last_login_180_days_to_365_days_ago.xlsx', index=False)"],"metadata":{"id":"EN-sdZRKMMWZ","executionInfo":{"status":"ok","timestamp":1712253423427,"user_tz":360,"elapsed":596,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# to grab the user audit report, go to EMR website --> setup --> report --> user audit report --> run report and save to location desired\n","\n","# Read the first Excel file containing the data\n","data_df = pd.read_excel('/content/User_Audit_Report_for_region_Colorado_03_29_2024.xlsx', skiprows=1)\n","\n","# Read the other Excel file containing the \"Username\" data\n","username_df = pd.read_excel('last_login_180_days_to_365_days_ago.xlsx')\n","\n","# Merge the filtered data with the \"resource\" data based on a common column (e.g., \"resource\")\n","merged_df = pd.merge(data_df, username_df, on='Username')\n","\n","# Write the merged data to a new Excel file\n","merged_df.to_excel('last_login_180_days_to_365_days_ago_update_combined_user_audit_report.xlsx', index=False)"],"metadata":{"id":"4DoFBCsQxguw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712253429857,"user_tz":360,"elapsed":1694,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}},"outputId":"f564611d-3858-4b5f-e4c1-dc5583e71d1b"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"]}]},{"cell_type":"markdown","source":["**8. creating data for the \"last login 180 days to 365 days ago\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"last login 180 days to 365 days ago\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","This code does a few things:\n","\n","1. It reads an Excel file called \"merged_data.xlsx\" into a DataFrame.\n","2. It removes duplicate rows based on the \"Username\" column.\n","3. It saves the cleaned data into a new Excel file called \"result.xlsx\".\n","4. It converts a column named \"Last login\" into datetime format.\n","5. It calculates today's date.\n","6. It calculates the date 180 days ago and the date 365 days ago from today's date.\n","7. It selects rows from the DataFrame where the \"Last login\" date falls between 180 and 365 days ago.\n","8. It saves the selected data into a new Excel file called \"last_login_180_days_to_365_days_ago.xlsx\".\n","\n","Overall, it cleans and filters data related to user logins and saves the filtered data into a new Excel file.\n","\n","Copy and paste results on this \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"s9e2H207RVA5"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('result.xlsx', index=False)"],"metadata":{"id":"iZXFN6p0NAtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming your DataFrame is named df and the column containing the last login dates is 'Last login'\n","# First, convert 'Last login' column to datetime if it's not already in datetime format\n","df['Date'] = pd.to_datetime(df['Last login'])\n","\n","# Then, calculate today's date\n","today = pd.to_datetime('today')\n","\n","# Calculate the date threshold for last login (365 days ago)\n","date_threshold = today - pd.DateOffset(days=365)\n","\n","# Select rows where last login is 365 days ago or more\n","filtered_df = df[df['Last login'] <= date_threshold]\n","\n","# Save the merged data to a new Excel file\n","filtered_df.to_excel('last_login_365_days_ago_and_more.xlsx', index=False)\n"],"metadata":{"id":"ymzFwbTjNA1X","executionInfo":{"status":"ok","timestamp":1712253742221,"user_tz":360,"elapsed":770,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# to grab the user audit report, go to EMR website --> setup --> report --> user audit report --> run report and save to location desired\n","\n","# Read the first Excel file containing the data\n","data_df = pd.read_excel('/content/User_Audit_Report_for_region_Colorado_03_29_2024.xlsx', skiprows=1)\n","\n","# Read the other Excel file containing the \"Username\" data\n","username_df = pd.read_excel('/content/last_login_365_days_ago_and_more.xlsx')\n","\n","# Merge the filtered data with the \"resource\" data based on a common column (e.g., \"resource\")\n","merged_df = pd.merge(data_df, username_df, on='Username')\n","\n","# Write the merged data to a new Excel file\n","merged_df.to_excel('last_login_365_days_ago_and_more_update_combined_user_audit_report.xlsx', index=False)"],"metadata":{"id":"adKTwxDzUFCN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712253751999,"user_tz":360,"elapsed":2239,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}},"outputId":"21375c12-4153-4c9b-c201-f5983601535f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"]}]},{"cell_type":"markdown","source":["**9. creating data for the \"all\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"all\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","This code does the following:\n","\n","1. It reads data from an Excel file named \"merged_data.xlsx\" and puts it into a DataFrame (think of it as a table in Python).\n","2. It removes any duplicate rows in the DataFrame based on the values in the \"Username\" column.\n","3. Finally, it saves the cleaned DataFrame into a new Excel file named \"result.xlsx\", without including the index column.\n","\n","Copy and paste results on this \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"ZXdksmRNSgUe"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('all.xlsx', index=False)"],"metadata":{"id":"A3flS3c_Sf-P","executionInfo":{"status":"ok","timestamp":1712254312971,"user_tz":360,"elapsed":205539,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["**10. creating data for the \"never logged - last updated\" tab**\n","\n","So here, we will use the output \"merged_data\" file to create the data for the \"never logged - last updated\" tab on this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\".\n","\n","This code does this:\n","\n","1. First, the code reads data from an Excel file called \"merged_data.xlsx\" and stores it in a DataFrame (a table-like structure used for data manipulation).\n","\n","2. It then removes any duplicate rows in the DataFrame based on the values in the \"Username\" column. This ensures each username is unique in the dataset.\n","\n","3. After removing duplicates, the cleaned data is saved to a new Excel file named \"result.xlsx\" without including the index column.\n","\n","4. Next, the code reads the data from the \"result.xlsx\" file into a new DataFrame.\n","\n","5. It checks for any blank values in the \"Last login\" column of the DataFrame.\n","\n","6. Finally, it saves the rows with blank values in the \"Last login\" column to a new Excel file named \"never_logged.xlsx\".\n","\n","In simpler terms, the code takes some data from an Excel file, cleans it up to remove duplicates, saves the cleaned-up version to a new file, then checks for any users who have never logged in and saves their information separately.\n","\n","Copy and paste results on this \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\""],"metadata":{"id":"lJ8cozr3S4va"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('result.xlsx', index=False)"],"metadata":{"id":"2k7q2YHHTJGc","executionInfo":{"status":"ok","timestamp":1712254773693,"user_tz":360,"elapsed":212723,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Read the first Excel file containing the data\n","df = pd.read_excel('/content/result.xlsx')\n","\n","# Check for blank values in the Last login column\n","blank_last_login = df[df['Last login'].isnull()]\n","\n","# Save the merged data to a new Excel file\n","blank_last_login.to_excel('never_logged.xlsx', index=False)"],"metadata":{"id":"z3QcusAyTJRm","executionInfo":{"status":"ok","timestamp":1712254784293,"user_tz":360,"elapsed":1339,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["**11. creating data for the \"never logged - last updated merged with User Audit Report dataset \" tab**\n","\n","This is for the never logged update report merged with user audit report dataset. So this is only to update the \"never logged - last updated\" tab in this spreadsheet \"https://docs.google.com/spreadsheets/d/1Qym5XWvc_o6zIj-kzoDGPc50KpmZa_KSc6pKtXTFgIQ/edit#gid=0\". You are just updating the column \"Last login\" tab to see who logged in after emailing them.\n","\n","This code does several things with Excel files using Python's pandas library:\n","\n","1. It starts by reading an Excel file named \"merged_data.xlsx\" into a DataFrame (a table-like data structure).\n","\n","2. It removes duplicate rows from the DataFrame based on the values in the \"Username\" column.\n","\n","3. It saves the cleaned DataFrame to a new Excel file named \"result.xlsx\".\n","\n","4. It checks for blank values in the \"Last login\" column of the DataFrame and creates a new DataFrame containing rows with blank \"Last login\" values.\n","\n","5. It saves the DataFrame with blank \"Last login\" values to a new Excel file named \"never_logged.xlsx\".\n","\n","6. It reads another Excel file named \"User_Audit_Report_for_region_Colorado_(date of when it was downloaded).xlsx\" **(data came from EMR --> setup --> user audit report --> download and upload to here)**, skipping the first row.\n","\n","7. It merges the data from the two DataFrames based on the \"Username\" column.\n","\n","8. It saves the merged DataFrame to a new Excel file named \"never_logged_update_combined_user_audit_report.xlsx\".\n"],"metadata":{"id":"rBPV4I0baGAH"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('result.xlsx', index=False)"],"metadata":{"id":"I6Kv5gDbaGN-","executionInfo":{"status":"ok","timestamp":1712255001375,"user_tz":360,"elapsed":212069,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Read the first Excel file containing the data\n","df = pd.read_excel('/content/result.xlsx')\n","\n","# Check for blank values in the Last login column\n","blank_last_login = df[df['Last login'].isnull()]\n","\n","# Save the merged data to a new Excel file\n","blank_last_login.to_excel('never_logged.xlsx', index=False)"],"metadata":{"id":"5BdnNuHtaGXS","executionInfo":{"status":"ok","timestamp":1712255035182,"user_tz":360,"elapsed":1135,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# to grab the user audit report, go to EMR website --> setup --> report --> user audit report --> run report and save to location desired\n","\n","# Read the first Excel file containing the data\n","data_df = pd.read_excel('/content/User_Audit_Report_for_region_Colorado_03_29_2024.xlsx', skiprows=1)\n","\n","# Read the other Excel file containing the \"Username\" data\n","username_df = pd.read_excel('/content/never_logged.xlsx')\n","\n","# Merge the filtered data with the \"resource\" data based on a common column (e.g., \"resource\")\n","merged_df = pd.merge(data_df, username_df, on='Username')\n","\n","# Write the merged data to a new Excel file\n","merged_df.to_excel('never_logged_update_combined_user_audit_report.xlsx', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmPupkceR-ky","executionInfo":{"status":"ok","timestamp":1712255041308,"user_tz":360,"elapsed":1750,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}},"outputId":"18cee31b-deac-4fb3-85a1-6e5cef17a5b2"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"]}]},{"cell_type":"markdown","source":["**12. creating data for the \"invalid users\" tab based on email**\n","\n","This code does the following:\n","\n","1. It reads data from an Excel file called \"merged_data.xlsx\" into a DataFrame (a table-like structure for data).\n","2. It removes duplicate rows from the DataFrame based on the values in the \"Username\" and \"Role\" columns.\n","3. It saves the cleaned data to a new Excel file named \"result.xlsx\".\n","4. It reads the data from \"result.xlsx\" into a DataFrame.\n","5. It filters the DataFrame to select rows where the value in the \"Status\" column is 'Invalid'.\n","6. It saves the filtered data to a new Excel file named \"invalid_df.xlsx\".\n","\n","So, in simple terms, it's cleaning up some data, removing duplicates, and then saving both the cleaned data and the rows marked as 'Invalid' to separate Excel files."],"metadata":{"id":"Td6phEjRIE7d"}},{"cell_type":"code","source":["# Read the Excel file into a DataFrame\n","excel_file = \"/content/merged_data.xlsx\"\n","df = pd.read_excel(excel_file)\n","\n","# Remove duplicates based on the \"Username\" column\n","df.drop_duplicates(subset=[\"Username\"], inplace=True)\n","\n","# Save the merged data to a new Excel file\n","df.to_excel('result.xlsx', index=False)"],"metadata":{"id":"OI0Qs567wsKf","executionInfo":{"status":"ok","timestamp":1712255251506,"user_tz":360,"elapsed":198335,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# Read the first Excel file containing the data\n","df = pd.read_excel('/content/result.xlsx')\n","\n","# Assuming df is your DataFrame and \"Status\" is the column name\n","invalid_df = df[df['Status'] == 'Invalid']\n","\n","# Write the merged data to a new Excel file\n","invalid_df.to_excel('invalid_df.xlsx', index=False)"],"metadata":{"id":"uga4HjhIxKmi","executionInfo":{"status":"ok","timestamp":1712255311898,"user_tz":360,"elapsed":2324,"user":{"displayName":"Diana Ir - CDPHE","userId":"15359322590399448091"}}},"execution_count":43,"outputs":[]}]}